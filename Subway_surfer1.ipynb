{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui as gui\n",
    "gui.PAUSE = 1\n",
    "import numpy as np\n",
    "gui.FAILSAFE = True\n",
    "import random\n",
    "import time\n",
    "import mouse as ms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = gui.getWindow('BlueStacks')\n",
    "pos = game.get_position()\n",
    "#possible_moves = np.identity(5,dtype='int').tolist()\n",
    "possible_moves = [0,1,2,3,4]\n",
    "possible_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 16, 429, 740)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = pos[2] - pos[0]\n",
    "ht = pos[3] - pos[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_x = pos[0]+np.round(ln*0.7185)\n",
    "replay_y = pos[1]+np.round(ht*0.86123)\n",
    "replay_rect_x = pos[0]\n",
    "replay_rect_y = pos[1]+np.round(ht*0.81598)\n",
    "replay_rect_ln = ln\n",
    "replay_rect_ht = np.round(ht*0.12)\n",
    "replay_image = gui.grab(region=(replay_rect_x,replay_rect_y,replay_rect_ln,replay_rect_ht))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "popup_x = pos[0] + np.round(ln*0.0479)\n",
    "popup_y = pos[1] + np.round(ht*0.22322)\n",
    "popup_ln = np.round(ln*0.1197)\n",
    "popup_ht = np.round(ht*0.06033)\n",
    "#popup_image = gui.grab(region=(popup_x,popup_y,popup_ln,popup_ht))\n",
    "popup_click_x = pos[0] + np.round(ln*0.107844)\n",
    "popup_click_y = pos[1] + np.round(ht*0.248868)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "popup_image = np.load('popup_image_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isdone():\n",
    "    replay_image_check = gui.grab(region=(replay_rect_x,replay_rect_y,replay_rect_ln,replay_rect_ht))\n",
    "    if replay_image_check == replay_image:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def popup_check_close():\n",
    "    popup_image_check = gui.grab(region=(popup_x,popup_y,popup_ln,popup_ht))\n",
    "    if np.array_equal(np.array(popup_image_check),popup_image):\n",
    "        ms.move(popup_click_x,popup_click_y)\n",
    "        ms.click()\n",
    "\n",
    "def replay():\n",
    "    replay_state = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(60,110))\n",
    "    ms.move(replay_x,replay_y)\n",
    "    ms.click()\n",
    "    return replay_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "popup_check_close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(i):\n",
    "    reward = 0\n",
    "    image_before = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(60,110))\n",
    "    if i == possible_moves[0]:\n",
    "        game.set_foreground()\n",
    "        gui.press('up')\n",
    "        \n",
    "    if i == possible_moves[1]:\n",
    "        game.set_foreground()\n",
    "        gui.press('down')\n",
    "        \n",
    "    if i == possible_moves[2]:\n",
    "        game.set_foreground()\n",
    "        gui.press('left')\n",
    "        \n",
    "    if i == possible_moves[3]:\n",
    "        game.set_foreground()\n",
    "        gui.press('right')\n",
    "        \n",
    "    if i == possible_moves[4]:\n",
    "        game.set_foreground()\n",
    "        pass\n",
    "        \n",
    "    image_after = cv2.resize(cv2.cvtColor(np.array(gui.grab(region=(pos[0],pos[1],ln,ht))), cv2.COLOR_BGR2GRAY),(60,110))\n",
    "    if isdone() == False:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = 0\n",
    "    return image_before,reward,isdone(),image_after\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "output_size = 5\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size,32,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=2,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=2,padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "        self.linear = nn.Linear(896,output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        return self.linear(x.view(x.size(0), -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:167: UserWarning: torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\n",
      "  warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.5996184107290472 episode_reward 149\n",
      "training\n",
      "loss 0.8106094318168873 episode_reward 121\n",
      "training\n",
      "loss 0.4015357714739215 episode_reward 141\n",
      "training\n",
      "loss 0.1187684505978921 episode_reward 146\n",
      "training\n",
      "loss 0.008081359690448412 episode_reward 154\n",
      "training\n",
      "loss 0.0008185203777135877 episode_reward 176\n",
      "training\n",
      "loss 7.363385221206393e-05 episode_reward 119\n",
      "training\n",
      "loss 9.525862660340258e-06 episode_reward 116\n",
      "training\n",
      "loss 2.4274463687204023e-06 episode_reward 108\n",
      "training\n",
      "loss 1.0195589339356726e-06 episode_reward 116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-dc9932a9a27f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpossible_moves\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#        move = np.random.choice([move,np.abs(1-move)],p=[1-epsilon,epsilon])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_done\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstate_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtraining_obs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-df1ef4ac9a57>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mimage_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mln\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-f7463c98e1e0>\u001b[0m in \u001b[0;36misdone\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0misdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mreplay_image_check\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplay_rect_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplay_rect_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplay_rect_ln\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplay_rect_ht\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreplay_image_check\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mreplay_image\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyscreeze\\__init__.py\u001b[0m in \u001b[0;36m_screenshot_win32\u001b[1;34m(imageFilename, region)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_screenshot_win32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageFilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageGrab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pillow module must be installed to use screenshot functions on Windows.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageGrab.py\u001b[0m in \u001b[0;36mgrab\u001b[1;34m(bbox)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;34m\"RGB\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m# RGB, 32-bit line padding, origin lower left corner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BGR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             )\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2328\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2330\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2331\u001b[0m     \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2332\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2292\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2294\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Net(input_size,output_size)\n",
    "net = net.double()\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "epsilon = 0.1\n",
    "while True:\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    state = replay()\n",
    "    reward = 0\n",
    "    episode_reward = 0\n",
    "    training_obs = []\n",
    "    training_acts = []\n",
    "    while True:\n",
    "        move_probs = sm(net(torch.from_numpy(state/255).reshape(-1,1,110,60))).tolist()[0]\n",
    "        move = np.random.choice(list(range(len(possible_moves))),p=move_probs)\n",
    "        move = possible_moves[move]\n",
    "#        move = np.random.choice([move,np.abs(1-move)],p=[1-epsilon,epsilon])\n",
    "        state,reward,is_done,state_after = step(move)\n",
    "        episode_reward += reward\n",
    "        training_obs.append(state)\n",
    "        training_acts.append(move)\n",
    "        popup_check_close()\n",
    "        if isdone():\n",
    "            ms.release()\n",
    "            training_obs = training_obs[0:-3]\n",
    "            training_acts = training_acts[0:-3]\n",
    "            \n",
    "            if len(training_acts) > 100:\n",
    "                print('training')\n",
    "                training_obs_v = torch.from_numpy(np.array(training_obs)/255)\n",
    "                training_acts_v = torch.from_numpy(np.array(training_acts))\n",
    "                optimizer.zero_grad()\n",
    "                action_scores_v = net(training_obs_v.reshape(-1,1, 110, 60))\n",
    "                loss_v = objective(action_scores_v, variable(training_acts_v).long())\n",
    "                loss_v.backward()\n",
    "                optimizer.step()\n",
    "                training_obs = []\n",
    "                training_acts = []\n",
    "                print('loss '+ str(loss_v.item()) + ' episode_reward '+ str(episode_reward))\n",
    "                episode_reward = 0\n",
    "            replay()\n",
    "    if episode_reward > 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
